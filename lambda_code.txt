import os
import json
import random
import requests
import boto3
import psycopg2
from datetime import datetime
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

# Constants and environment variables
NEWS_API_KEY = os.getenv('NEWS_API_KEY')
NEWS_API_URL = 'https://newsapi.org/v2/everything'
S3_BUCKET_NAME = os.getenv('S3_BUCKET_NAME')

# RDS/PostgreSQL Database credentials
DB_HOST = os.getenv('DB_HOST')
DB_NAME = os.getenv('DB_NAME')
DB_USER = os.getenv('DB_USER')
DB_PASSWORD = os.getenv('DB_PASSWORD')

# Initialize S3 client and sentiment analyzer
s3 = boto3.client('s3')
analyzer = SentimentIntensityAnalyzer()

def fetch_news():
    """Fetch up to 100 news articles from the News API with varied topics."""
    if not NEWS_API_KEY:
        print("Error: NEWS_API_KEY environment variable is missing.")
        return []
    
    # List of topics to fetch news for, to ensure a variety of sentiments
    topics = ['technology', 'politics', 'finance', 'health', 'entertainment']
    selected_topic = random.choice(topics)  # Choose a random topic

    params = {
        'q': selected_topic,    # Use a random topic each run
        'pageSize': 100,
        'sortBy': 'publishedAt',
        'language': 'en',
        'apiKey': NEWS_API_KEY
    }

    try:
        response = requests.get(NEWS_API_URL, params=params)
        if response.status_code == 200:
            articles = response.json().get('articles', [])
            return articles if articles else []
        elif response.status_code == 429:
            print("Rate limit exceeded. Try again later.")
        else:
            print(f"Failed to fetch news. Status code: {response.status_code}, Message: {response.text}")
    except requests.exceptions.RequestException as e:
        print(f"Request failed: {e}")
    return []

def analyze_sentiment(article_content):
    """Perform sentiment analysis using VADER with detailed sentiment categories."""
    sentiment_scores = analyzer.polarity_scores(article_content)
    compound_score = sentiment_scores['compound']
    
    # Use more nuanced sentiment ranges
    if compound_score >= 0.2:
        sentiment_label = "positive"
    elif compound_score <= -0.2:
        sentiment_label = "negative"
    else:
        sentiment_label = "neutral"

    return compound_score, sentiment_label

def store_in_rds(articles):
    """Store articles with sentiment scores in RDS PostgreSQL."""
    try:
        conn = psycopg2.connect(
            host=DB_HOST,
            database=DB_NAME,
            user=DB_USER,
            password=DB_PASSWORD
        )
        cursor = conn.cursor()
        
        for article in articles:
            cursor.execute(""" 
                INSERT INTO news_articles (title, description, url, published_at, sentiment, sentiment_score)
                VALUES (%s, %s, %s, %s, %s, %s)
            """, (
                article['title'],
                article['description'],
                article['url'],
                article['publishedAt'],
                article['sentiment_label'],
                article['sentiment_score']
            ))

        conn.commit()
        cursor.close()
        conn.close()
    except Exception as e:
        print(f"Error storing data in RDS: {e}")
        raise

def store_in_s3(articles):
    """Store raw articles data in S3 as a JSON file."""
    file_name = f"news_articles_{datetime.now().strftime('%Y%m%d%H%M%S')}.json"
    try:
        s3.put_object(
            Bucket=S3_BUCKET_NAME,
            Key=file_name,
            Body=json.dumps(articles),
            ContentType='application/json'
        )
        print(f"Stored raw news data in S3 bucket '{S3_BUCKET_NAME}' as '{file_name}'")
    except Exception as e:
        print(f"Error storing data in S3: {e}")
        raise

def lambda_handler(event, context):
    # Step 1: Fetch news articles from the API
    print(f"Using API URL: {NEWS_API_URL}")
    articles = fetch_news()
    
    if not articles:
        return {"statusCode": 500, "body": json.dumps("No articles fetched.")}

    # Step 2: Perform sentiment analysis on each article
    sentiment_counts = {"positive": 0, "neutral": 0, "negative": 0}
    for article in articles:
        content = article.get('description', '')  # Use description as content for sentiment analysis
        sentiment_score, sentiment_label = analyze_sentiment(content)
        article['sentiment_score'] = sentiment_score
        article['sentiment_label'] = sentiment_label
        
        # Update count of each sentiment type
        sentiment_counts[sentiment_label] += 1

    print(f"Sentiment distribution: {sentiment_counts}")  # Log the distribution

    # Step 3: Store processed articles in RDS
    try:
        store_in_rds(articles)
    except Exception as e:
        return {"statusCode": 500, "body": json.dumps(f"Failed to store data in RDS: {str(e)}")}

    # Step 4: Store raw articles in S3
    try:
        store_in_s3(articles)
    except Exception as e:
        return {"statusCode": 500, "body": json.dumps(f"Failed to store data in S3: {str(e)}")}

    # Return success response
    return {"statusCode": 200, "body": json.dumps(f"Processed {len(articles)} articles successfully.")}
